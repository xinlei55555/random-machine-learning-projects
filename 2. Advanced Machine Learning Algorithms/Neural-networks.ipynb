{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#If I didn't want to write tf.keras.dense, I could\n",
    "#from tensorflow.keras.layers import Dense\n",
    "#same for sequential\n",
    "#from tensorflow.keras import Sequential\n",
    "\n",
    "ls = np.array([[1,2,3,4,5,6]])\n",
    "\n",
    "print(ls[:,3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision numpy arrays:\n",
    "The brackets of the numpy array define the matrix that is outputted \n",
    "\n",
    "(Tensorflow's convention is to use 2D matrices (not 1D vectors))\n",
    "\n",
    "\n",
    "<img src='precision_numpy_arrays.jpg'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######### NOTE!\n",
    "\n",
    "what I just implemented in the next two blocks of code is NOT neural Networks!\n",
    "\n",
    "I just did forward propagation (which is simply a dot product, with a sigmoid function)\n",
    "\n",
    "There, I did not implement gradient descent, nor loss (which are in the compile part)\n",
    "\n",
    "Thus, if I run the same thing over and over again, the only reason why it doesn't give me the same thing, is because tensorflow is setting the INITIAL weights of the dense layesr RANDOMLY (see onenote document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[200.0, 17.0]])\n",
    "\n",
    "#units = number of neurons in the layer\n",
    "# activation function is the type of function I want (in my case, logistic regression) \n",
    "layer_1 = tf.keras.layers.Dense(units=3, activation=\"sigmoid\")\n",
    "\n",
    "#i am applying the layer I created on x\n",
    "activation1 = layer_1(x)\n",
    "\n",
    "#output layer\n",
    "layer_2 = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
    "\n",
    "a2 = layer_2(activation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n",
      "The actual output found was:  tf.Tensor([[0.1986365]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#setting the boundary\n",
    "\n",
    "if a2 >= 0.5:\n",
    "    print(\"true\")\n",
    "\n",
    "else:\n",
    "    print(\"false\")\n",
    "\n",
    "\n",
    "#this means that the output was a shape=(1,1) ==> a 1x1 2D matrix\n",
    "print(\"The actual output found was: \", a2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the data, we have a 2D array of inputs (matrix)\n",
    "and\n",
    "\n",
    "a 1D array of expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ([[200.0, 17.0],[120.0, 5.0], [425.0, 20.0], [300.0, 10.0]])\n",
    "y_train = ([[1.0],[0.0],[0.0],[1.0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of proceeding is to directly agence many layers together (I had created layer 1 followed by layer 2)\n",
    "\n",
    "Instead, we could create Sequential\n",
    "\n",
    "(this sequential directly links both layers together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([layer_1, layer_2])\n",
    "\n",
    "#or, just write (instead of saving values layer_1 and layer_2)\n",
    "#model = tf.keras.Sequential([\n",
    "        # Dense(units=3, activation=\"sigmoid\"),\n",
    "        # Dense(units=1, activation=\"sigmoid\")])\n",
    "\n",
    "\n",
    "\n",
    "#in compile, you just tell him the type of loss function you wants\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "model.compile(loss=BinaryCrossentropy())\n",
    "\n",
    "#or model.compile(loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8535\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17605f5d4c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"d:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_6' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (None, 1)\n    \n    Call arguments received by layer 'sequential_6' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=int32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#predicting:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m x_new\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray([[\u001b[39m10000\u001b[39m]])\n\u001b[1;32m----> 4\u001b[0m model\u001b[39m.\u001b[39;49mpredict(x_new)\n",
      "File \u001b[1;32md:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file1ofr2ukh.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"d:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Programs\\Anaconda\\envs\\conda_env\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_6' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (None, 1)\n    \n    Call arguments received by layer 'sequential_6' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=int32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "#predicting:\n",
    "x_new=np.array([[10000]])\n",
    "\n",
    "model.predict(x_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
